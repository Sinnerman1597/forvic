{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9b0f8036",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loudness  speechiness  liveness\n",
      "0  3.850998     0.042005  0.108854\n",
      "1  3.846140     0.025473  0.092944\n",
      "2  3.770160     0.031789  0.085719\n",
      "3  3.855516     0.035657  0.076683\n",
      "4  3.945052     0.029753  0.104360\n",
      "   loudness  speechiness  acousticness  instrumentalness  liveness     tempo\n",
      "0 -0.168131    -0.493702      1.147992         -0.626560 -0.533321  0.389511\n",
      "1 -0.203317    -0.730969      0.509050         -0.626521 -0.649405  0.616316\n",
      "2 -0.753539    -0.640317      0.099774         -0.626417 -0.702117  0.604601\n",
      "3 -0.135414    -0.584814      1.480713         -0.626560 -0.768041  2.784583\n",
      "4  0.512974    -0.669542     -0.681678         -0.571383 -0.566112  1.676768\n",
      "0         1\n",
      "1         1\n",
      "2         1\n",
      "3         1\n",
      "4         1\n",
      "         ..\n",
      "518979    0\n",
      "518980    0\n",
      "518981    0\n",
      "518982    0\n",
      "518983    0\n",
      "Name: popularity, Length: 518984, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "a_url = 'C:/Users/User/Downloads/processed_data.csv'\n",
    "one_m_data = pd.read_csv(a_url)\n",
    "\n",
    "one_m_data['audio_mode'] = one_m_data['mode']\n",
    "one_m_data.audio_mode= one_m_data.audio_mode.astype(float)\n",
    "\n",
    "threshold = one_m_data['popularity'].quantile(0.75)\n",
    "\n",
    "# 選擇人氣度前25%的歌曲\n",
    "top_25p_songs = one_m_data[one_m_data['popularity'] >= threshold]\n",
    "\n",
    "# num_of_songs = len(top_25p_songs)\n",
    "# num_of_songs\n",
    "\n",
    "# 選擇人氣度後75%的歌曲\n",
    "random_seed = 42\n",
    "bot_75p_songs = one_m_data[one_m_data['popularity'] < threshold]\n",
    "\n",
    "# 從人氣度後75%的歌曲中隨機挑選與前25%數量相同的歌曲\n",
    "random_seed = 42\n",
    "sam_75p_songs = bot_75p_songs.sample(n=len(top_25p_songs))\n",
    "\n",
    "# 合併上述兩個子集以創建新的DataFrame\n",
    "one_m_data = pd.concat([top_25p_songs, sam_75p_songs], axis=0).reset_index(drop=True)\n",
    "\n",
    "# one_m_data.shape\n",
    "\n",
    "# 要取對數的特征列表\n",
    "features_to_log = ['loudness', 'speechiness', 'liveness']\n",
    "\n",
    "# 為了避免負值和零，對 loudness 進行正值轉換，因為它可能有負值\n",
    "one_m_data['loudness'] = one_m_data['loudness'] - one_m_data['loudness'].min() + 1\n",
    "one_m_data['speechiness'] = one_m_data['speechiness'] - one_m_data['speechiness'].min() + 1\n",
    "one_m_data['liveness'] = one_m_data['liveness'] - one_m_data['liveness'].min() + 1\n",
    "\n",
    "# 對這些特徵取對數，並在取對數之前加上一個很小的正數\n",
    "epsilon = 1e-10\n",
    "for feature in features_to_log:\n",
    "    one_m_data[feature] = np.log(one_m_data[feature] + epsilon)\n",
    "\n",
    "# 顯示轉換後的特徵的前幾行\n",
    "print(one_m_data[features_to_log].head())\n",
    "\n",
    "# Features to standardize\n",
    "features_to_standardize = ['loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'tempo']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the standardization to the f_engineering dataframe\n",
    "one_m_data[features_to_standardize] = scaler.fit_transform(one_m_data[features_to_standardize])\n",
    "\n",
    "# Display the first few rows of the standardized features\n",
    "print(one_m_data[features_to_standardize].head())\n",
    "\n",
    "one_m_data[\"popularity\"]= [ 1 if i>=40 else 0 for i in one_m_data.popularity ]\n",
    "one_m_data[\"popularity\"].value_counts()\n",
    "print(one_m_data[\"popularity\"])\n",
    "\n",
    "# one_m_data[\"key\"] = one_m_data[\"key\"].astype(\"category\")\n",
    "# one_m_data = pd.get_dummies(one_m_data, columns=[\"key\"])\n",
    "# one_m_data[\"key_0\"] = one_m_data[\"key_0\"].astype(int)\n",
    "# one_m_data[\"key_1\"] = one_m_data[\"key_1\"].astype(int)\n",
    "# one_m_data[\"key_2\"] = one_m_data[\"key_2\"].astype(int)\n",
    "# one_m_data[\"key_3\"] = one_m_data[\"key_3\"].astype(int)\n",
    "# one_m_data[\"key_4\"] = one_m_data[\"key_4\"].astype(int)\n",
    "# one_m_data[\"key_5\"] = one_m_data[\"key_5\"].astype(int)\n",
    "# one_m_data[\"key_6\"] = one_m_data[\"key_6\"].astype(int)\n",
    "# one_m_data[\"key_7\"] = one_m_data[\"key_7\"].astype(int)\n",
    "# one_m_data[\"key_8\"] = one_m_data[\"key_8\"].astype(int)\n",
    "# one_m_data[\"key_9\"] = one_m_data[\"key_9\"].astype(int)\n",
    "# one_m_data[\"key_10\"] = one_m_data[\"key_10\"].astype(int)\n",
    "# one_m_data[\"key_11\"] = one_m_data[\"key_11\"].astype(int)\n",
    "# one_m_data.head()\n",
    "\n",
    "# one_m_data[\"audio_mode\"] = one_m_data[\"audio_mode\"].astype(\"category\")\n",
    "# one_m_data = pd.get_dummies(one_m_data, columns=[\"audio_mode\"])\n",
    "# one_m_data[\"audio_mode_0.0\"] = one_m_data[\"audio_mode_0.0\"].astype(int)\n",
    "# one_m_data[\"audio_mode_1.0\"] = one_m_data[\"audio_mode_1.0\"].astype(int)\n",
    "# one_m_data.head()\n",
    "\n",
    "# one_m_data.drop(['year','mode'],axis=1,inplace=True)\n",
    "# one_m_data.columns[one_m_data.isnull().any()]\n",
    "\n",
    "# # one_m_data.to_csv(one_m_data.csv, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b73c80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
