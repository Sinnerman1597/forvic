{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "52192d87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loudness  speechiness  liveness\n",
      "0  3.765771     0.042005  0.108854\n",
      "1  3.760479     0.025473  0.092944\n",
      "2  3.677414     0.031789  0.085719\n",
      "3  3.770690     0.035657  0.076683\n",
      "4  3.867778     0.029753  0.104360\n",
      "   loudness  speechiness  acousticness  instrumentalness  liveness     tempo\n",
      "0 -0.154865    -0.493486      1.146309         -0.627155 -0.533055  0.390042\n",
      "1 -0.189139    -0.731439      0.507700         -0.627116 -0.649024  0.617059\n",
      "2 -0.727106    -0.640525      0.098637         -0.627012 -0.701684  0.605333\n",
      "3 -0.123009    -0.584862      1.478856         -0.627155 -0.767542  2.787356\n",
      "4  0.505782    -0.669835     -0.682408         -0.571985 -0.565814  1.678504\n",
      "Best Parameters: {'learning_rate': 0.05, 'max_depth': 11, 'n_estimators': 200}\n",
      "Mean Squared Error (MSE): 0.14\n",
      "R-squared (R2): 0.26\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "import xgboost as xgb\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "a_url = 'C:/Users/User/Downloads/processed_data.csv'\n",
    "one_m_data = pd.read_csv(a_url)\n",
    "\n",
    "one_m_data['audio_mode'] = one_m_data['mode']\n",
    "one_m_data.audio_mode= one_m_data.audio_mode.astype(float)\n",
    "\n",
    "threshold = one_m_data['popularity'].quantile(0.75)\n",
    "\n",
    "# 選擇人氣度前25%的歌曲\n",
    "top_25p_songs = one_m_data[one_m_data['popularity'] >= threshold]\n",
    "\n",
    "# num_of_songs = len(top_25p_songs)\n",
    "# num_of_songs\n",
    "\n",
    "# 選擇人氣度後75%的歌曲\n",
    "random_seed = 42\n",
    "bot_75p_songs = one_m_data[one_m_data['popularity'] < threshold]\n",
    "\n",
    "# 從人氣度後75%的歌曲中隨機挑選與前25%數量相同的歌曲\n",
    "random_seed = 42\n",
    "sam_75p_songs = bot_75p_songs.sample(n=len(top_25p_songs))\n",
    "\n",
    "# 合併上述兩個子集以創建新的DataFrame\n",
    "one_m_data = pd.concat([top_25p_songs, sam_75p_songs], axis=0).reset_index(drop=True)\n",
    "\n",
    "# one_m_data.shape\n",
    "\n",
    "# 要取對數的特征列表\n",
    "features_to_log = ['loudness', 'speechiness', 'liveness']\n",
    "\n",
    "# 為了避免負值和零，對 loudness 進行正值轉換，因為它可能有負值\n",
    "one_m_data['loudness'] = one_m_data['loudness'] - one_m_data['loudness'].min() + 1\n",
    "one_m_data['speechiness'] = one_m_data['speechiness'] - one_m_data['speechiness'].min() + 1\n",
    "one_m_data['liveness'] = one_m_data['liveness'] - one_m_data['liveness'].min() + 1\n",
    "\n",
    "# 對這些特徵取對數，並在取對數之前加上一個很小的正數\n",
    "epsilon = 1e-10\n",
    "for feature in features_to_log:\n",
    "    one_m_data[feature] = np.log(one_m_data[feature] + epsilon)\n",
    "\n",
    "# 顯示轉換後的特徵的前幾行\n",
    "print(one_m_data[features_to_log].head())\n",
    "\n",
    "# Features to standardize\n",
    "features_to_standardize = ['loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'tempo']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the standardization to the f_engineering dataframe\n",
    "one_m_data[features_to_standardize] = scaler.fit_transform(one_m_data[features_to_standardize])\n",
    "\n",
    "# Display the first few rows of the standardized features\n",
    "print(one_m_data[features_to_standardize].head())\n",
    "\n",
    "one_m_data[\"popularity\"]= [ 1 if i>=40 else 0 for i in one_m_data.popularity ]\n",
    "one_m_data[\"popularity\"].value_counts()\n",
    "\n",
    "one_m_data[\"key\"] = one_m_data[\"key\"].astype(\"category\")\n",
    "one_m_data = pd.get_dummies(one_m_data, columns=[\"key\"])\n",
    "one_m_data[\"key_0\"] = one_m_data[\"key_0\"].astype(int)\n",
    "one_m_data[\"key_1\"] = one_m_data[\"key_1\"].astype(int)\n",
    "one_m_data[\"key_2\"] = one_m_data[\"key_2\"].astype(int)\n",
    "one_m_data[\"key_3\"] = one_m_data[\"key_3\"].astype(int)\n",
    "one_m_data[\"key_4\"] = one_m_data[\"key_4\"].astype(int)\n",
    "one_m_data[\"key_5\"] = one_m_data[\"key_5\"].astype(int)\n",
    "one_m_data[\"key_6\"] = one_m_data[\"key_6\"].astype(int)\n",
    "one_m_data[\"key_7\"] = one_m_data[\"key_7\"].astype(int)\n",
    "one_m_data[\"key_8\"] = one_m_data[\"key_8\"].astype(int)\n",
    "one_m_data[\"key_9\"] = one_m_data[\"key_9\"].astype(int)\n",
    "one_m_data[\"key_10\"] = one_m_data[\"key_10\"].astype(int)\n",
    "one_m_data[\"key_11\"] = one_m_data[\"key_11\"].astype(int)\n",
    "one_m_data.head()\n",
    "\n",
    "one_m_data[\"audio_mode\"] = one_m_data[\"audio_mode\"].astype(\"category\")\n",
    "one_m_data = pd.get_dummies(one_m_data, columns=[\"audio_mode\"])\n",
    "one_m_data[\"audio_mode_0.0\"] = one_m_data[\"audio_mode_0.0\"].astype(int)\n",
    "one_m_data[\"audio_mode_1.0\"] = one_m_data[\"audio_mode_1.0\"].astype(int)\n",
    "one_m_data.head()\n",
    "\n",
    "one_m_data.drop(['mode'],axis=1,inplace=True)\n",
    "one_m_data.columns[one_m_data.isnull().any()]\n",
    "\n",
    "y = one_m_data[\"popularity\"].values\n",
    "X = one_m_data.drop([\"popularity\"],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xgbr = xgb.XGBRegressor(objective=\"reg:squarederror\", random_state=42)\n",
    "\n",
    "param_grid = {\n",
    "    'max_depth': [3, 5, 7, 9, 11],\n",
    "    'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "    'n_estimators': [50, 75, 100, 150, 200]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(xgbr, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_xgbr = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_xgbr.predict(X_test)\n",
    "\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "\n",
    "# 尚未切分資料集前的結果\n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 5, 7, 9, 11],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "#     'n_estimators': [50, 75, 100, 150, 200]\n",
    "# }\n",
    "# Best Parameters: {'learning_rate': 0.1, 'max_depth': 11, 'n_estimators': 200}\n",
    "# Mean Squared Error (MSE): 164.85\n",
    "# R-squared (R2): 0.29\n",
    "\n",
    "# 切分資料集後的結果\n",
    "# param_grid = {\n",
    "#     'max_depth': [3, 5, 7, 9, 11],\n",
    "#     'learning_rate': [0.01, 0.05, 0.1, 0.3, 0.5],\n",
    "#     'n_estimators': [50, 75, 100, 150, 200]\n",
    "# }\n",
    "# Best Parameters: {'learning_rate': 0.05, 'max_depth': 11, 'n_estimators': 200}\n",
    "# Mean Squared Error (MSE): 195.48\n",
    "# R-squared (R2): 0.31"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c64e98f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
