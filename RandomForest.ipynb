{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "43c8edcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   loudness  speechiness  liveness\n",
      "0  3.892677     0.042005  0.108854\n",
      "1  3.888017     0.025473  0.092944\n",
      "2  3.815270     0.031789  0.085719\n",
      "3  3.897011     0.035657  0.076683\n",
      "4  3.983059     0.029753  0.104360\n",
      "   loudness  speechiness  acousticness  instrumentalness  liveness     tempo\n",
      "0 -0.170719    -0.493353      1.148285         -0.626830 -0.532680  0.390605\n",
      "1 -0.206148    -0.730931      0.509237         -0.626790 -0.648917  0.617753\n",
      "2 -0.759252    -0.640160      0.099893         -0.626687 -0.701700  0.606020\n",
      "3 -0.137768    -0.584585      1.481061         -0.626830 -0.767711  2.789303\n",
      "4  0.516463    -0.669423     -0.681689         -0.571648 -0.565514  1.679811\n",
      "Best Parameters: {'max_depth': 20, 'n_estimators': 200}\n",
      "Mean Squared Error (MSE): 0.14\n",
      "R-squared (R2): 0.25\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "a_url = 'C:/Users/User/Downloads/processed_data.csv'\n",
    "one_m_data = pd.read_csv(a_url)\n",
    "\n",
    "one_m_data['audio_mode'] = one_m_data['mode']\n",
    "one_m_data.audio_mode= one_m_data.audio_mode.astype(float)\n",
    "\n",
    "threshold = one_m_data['popularity'].quantile(0.75)\n",
    "\n",
    "# 選擇人氣度前25%的歌曲\n",
    "top_25p_songs = one_m_data[one_m_data['popularity'] >= threshold]\n",
    "\n",
    "# num_of_songs = len(top_25p_songs)\n",
    "# num_of_songs\n",
    "\n",
    "# 選擇人氣度後75%的歌曲\n",
    "random_seed = 42\n",
    "bot_75p_songs = one_m_data[one_m_data['popularity'] < threshold]\n",
    "\n",
    "# 從人氣度後75%的歌曲中隨機挑選與前25%數量相同的歌曲\n",
    "random_seed = 42\n",
    "sam_75p_songs = bot_75p_songs.sample(n=len(top_25p_songs))\n",
    "\n",
    "# 合併上述兩個子集以創建新的DataFrame\n",
    "one_m_data = pd.concat([top_25p_songs, sam_75p_songs], axis=0).reset_index(drop=True)\n",
    "\n",
    "# one_m_data.shape\n",
    "\n",
    "# 要取對數的特征列表\n",
    "features_to_log = ['loudness', 'speechiness', 'liveness']\n",
    "\n",
    "# 為了避免負值和零，對 loudness 進行正值轉換，因為它可能有負值\n",
    "one_m_data['loudness'] = one_m_data['loudness'] - one_m_data['loudness'].min() + 1\n",
    "one_m_data['speechiness'] = one_m_data['speechiness'] - one_m_data['speechiness'].min() + 1\n",
    "one_m_data['liveness'] = one_m_data['liveness'] - one_m_data['liveness'].min() + 1\n",
    "\n",
    "# 對這些特徵取對數，並在取對數之前加上一個很小的正數\n",
    "epsilon = 1e-10\n",
    "for feature in features_to_log:\n",
    "    one_m_data[feature] = np.log(one_m_data[feature] + epsilon)\n",
    "\n",
    "# 顯示轉換後的特徵的前幾行\n",
    "print(one_m_data[features_to_log].head())\n",
    "\n",
    "# Features to standardize\n",
    "features_to_standardize = ['loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'tempo']\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Apply the standardization to the f_engineering dataframe\n",
    "one_m_data[features_to_standardize] = scaler.fit_transform(one_m_data[features_to_standardize])\n",
    "\n",
    "# Display the first few rows of the standardized features\n",
    "print(one_m_data[features_to_standardize].head())\n",
    "\n",
    "one_m_data[\"popularity\"]= [ 1 if i>=40 else 0 for i in one_m_data.popularity ]\n",
    "one_m_data[\"popularity\"].value_counts()\n",
    "\n",
    "one_m_data[\"key\"] = one_m_data[\"key\"].astype(\"category\")\n",
    "one_m_data = pd.get_dummies(one_m_data, columns=[\"key\"])\n",
    "one_m_data[\"key_0\"] = one_m_data[\"key_0\"].astype(int)\n",
    "one_m_data[\"key_1\"] = one_m_data[\"key_1\"].astype(int)\n",
    "one_m_data[\"key_2\"] = one_m_data[\"key_2\"].astype(int)\n",
    "one_m_data[\"key_3\"] = one_m_data[\"key_3\"].astype(int)\n",
    "one_m_data[\"key_4\"] = one_m_data[\"key_4\"].astype(int)\n",
    "one_m_data[\"key_5\"] = one_m_data[\"key_5\"].astype(int)\n",
    "one_m_data[\"key_6\"] = one_m_data[\"key_6\"].astype(int)\n",
    "one_m_data[\"key_7\"] = one_m_data[\"key_7\"].astype(int)\n",
    "one_m_data[\"key_8\"] = one_m_data[\"key_8\"].astype(int)\n",
    "one_m_data[\"key_9\"] = one_m_data[\"key_9\"].astype(int)\n",
    "one_m_data[\"key_10\"] = one_m_data[\"key_10\"].astype(int)\n",
    "one_m_data[\"key_11\"] = one_m_data[\"key_11\"].astype(int)\n",
    "one_m_data.head()\n",
    "\n",
    "one_m_data[\"audio_mode\"] = one_m_data[\"audio_mode\"].astype(\"category\")\n",
    "one_m_data = pd.get_dummies(one_m_data, columns=[\"audio_mode\"])\n",
    "one_m_data[\"audio_mode_0.0\"] = one_m_data[\"audio_mode_0.0\"].astype(int)\n",
    "one_m_data[\"audio_mode_1.0\"] = one_m_data[\"audio_mode_1.0\"].astype(int)\n",
    "one_m_data.head()\n",
    "\n",
    "one_m_data.drop(['mode'],axis=1,inplace=True)\n",
    "one_m_data.columns[one_m_data.isnull().any()]\n",
    "\n",
    "y = one_m_data[\"popularity\"].values\n",
    "X = one_m_data.drop([\"popularity\"],axis=1)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "regressor = RandomForestRegressor(random_state=42)\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [None, 10, 20, 30]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(regressor, param_grid, cv=5, scoring='neg_mean_squared_error', n_jobs=-1)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "\n",
    "best_regressor = grid_search.best_estimator_\n",
    "\n",
    "y_pred = best_regressor.predict(X_test_scaled)\n",
    "\n",
    "mse = -grid_search.best_score_  \n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Best Parameters:\", grid_search.best_params_)\n",
    "print(f\"Mean Squared Error (MSE): {mse:.2f}\")\n",
    "print(f\"R-squared (R2): {r2:.2f}\")\n",
    "\n",
    "# 尚未切分資料集前的結果\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30]\n",
    "# }\n",
    "# Best Parameters: {'max_depth': 30, 'n_estimators': 200}\n",
    "# Mean Squared Error (MSE): 169.67\n",
    "# R-squared (R2): 0.28\n",
    "\n",
    "# 切分資料集後的結果\n",
    "# param_grid = {\n",
    "#     'n_estimators': [50, 100, 200],\n",
    "#     'max_depth': [None, 10, 20, 30]\n",
    "# }\n",
    "# Best Parameters: {'max_depth': 30, 'n_estimators': 200}\n",
    "# Mean Squared Error (MSE): 199.46\n",
    "# R-squared (R2): 0.30"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
